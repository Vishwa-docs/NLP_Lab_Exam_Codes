{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./resources/tam.txt\", encoding=\"utf8\") as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "\n",
    "X_txt = []\n",
    "y_txt = []\n",
    "\n",
    "X_voc = set()\n",
    "y_voc = set()\n",
    "    \n",
    "for line in data:\n",
    "    # Skip In-Valid Seq\n",
    "    if(len(line.split(\"\\t\")) != 3):\n",
    "        continue\n",
    "    \n",
    "    target, inp, _ = line.split(\"\\t\")\n",
    "    target = \"\\t\" + target + \"\\n\" # \"\\t\" -> Start Seq, \"\\n\" -> End Seq\n",
    "    \n",
    "    X_txt.append(inp)\n",
    "    y_txt.append(target)\n",
    "    \n",
    "    X_voc.update(set(inp))\n",
    "    y_voc.update(set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Records :  201\n",
      "\n",
      "Vocab Size of Input tok :  52\n",
      "vocab Size of Output tok :  55\n",
      "\n",
      "Max Seq length for input :  109\n",
      "Max Seq length for output :  96\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Records : \", len(X_txt), end=\"\\n\\n\")\n",
    "\n",
    "X_voc = sorted(list(X_voc))\n",
    "y_voc = sorted(list(y_voc))\n",
    "\n",
    "print(\"Vocab Size of Input tok : \", len(X_voc))\n",
    "print(\"vocab Size of Output tok : \", len(y_voc), end=\"\\n\\n\")\n",
    "\n",
    "max_encoder = max([len(t) for t in X_txt])\n",
    "max_decoder = max([len(t) for t in y_txt])\n",
    "\n",
    "print(\"Max Seq length for input : \", max_encoder)\n",
    "print(\"Max Seq length for output : \", max_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "input_tok_enc = dict([(char, i) for i, char in enumerate(X_voc)])\n",
    "input_tok_dec = dict([(i, char) for i, char in enumerate(X_voc)])\n",
    "\n",
    "target_tok_enc = dict([(char, i) for i, char in enumerate(y_voc)])\n",
    "target_tok_dec = dict([(i, char) for i, char in enumerate(y_voc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[input_tok_enc[char] for char in text] for text in X_txt]\n",
    "y = [[target_tok_enc[char] for char in text] for text in y_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_encoder, padding=\"post\", value=input_tok_enc[' '])\n",
    "y = pad_sequences(y, maxlen=max_decoder, padding=\"post\", value=target_tok_enc[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, CategoryEncoding\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder Block\n",
    "encoder_inputs = Input(shape=(None, len(X_voc)))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder Block\n",
    "decoder_inputs = (Input(shape=(None, len(y_voc))))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(y_voc), activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">316,416</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">319,488</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,135</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m316,416\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m319,488\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)  │     \u001b[38;5;34m14,135\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,039</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650,039\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,039</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m650,039\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - accuracy: 0.0941 - loss: 3.9504 - val_accuracy: 0.6509 - val_loss: 3.5725\n",
      "Epoch 2/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.8095 - loss: 3.2199 - val_accuracy: 0.6509 - val_loss: 1.9109\n",
      "Epoch 3/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - accuracy: 0.8100 - loss: 1.1676 - val_accuracy: 0.6509 - val_loss: 2.4270\n",
      "Epoch 4/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8110 - loss: 1.1048 - val_accuracy: 0.6471 - val_loss: 2.0326\n",
      "Epoch 5/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - accuracy: 0.6287 - loss: 1.9220 - val_accuracy: 0.6502 - val_loss: 2.0138\n",
      "Epoch 6/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8085 - loss: 0.9252 - val_accuracy: 0.6509 - val_loss: 2.1377\n",
      "Epoch 7/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - accuracy: 0.8107 - loss: 0.9767 - val_accuracy: 0.6509 - val_loss: 2.0064\n",
      "Epoch 8/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - accuracy: 0.8101 - loss: 0.9381 - val_accuracy: 0.6509 - val_loss: 1.7964\n",
      "Epoch 9/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.8100 - loss: 0.8863 - val_accuracy: 0.6509 - val_loss: 1.6347\n",
      "Epoch 10/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.8083 - loss: 0.8881 - val_accuracy: 0.6509 - val_loss: 1.5561\n",
      "Epoch 11/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.8104 - loss: 0.8625 - val_accuracy: 0.6509 - val_loss: 1.5434\n",
      "Epoch 12/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - accuracy: 0.8079 - loss: 0.8109 - val_accuracy: 0.6509 - val_loss: 1.6263\n",
      "Epoch 13/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - accuracy: 0.8088 - loss: 0.7775 - val_accuracy: 0.6509 - val_loss: 1.6898\n",
      "Epoch 14/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - accuracy: 0.8086 - loss: 0.7612 - val_accuracy: 0.6509 - val_loss: 1.6358\n",
      "Epoch 15/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - accuracy: 0.8096 - loss: 0.7435 - val_accuracy: 0.6509 - val_loss: 1.5860\n",
      "Epoch 16/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.8082 - loss: 0.7434 - val_accuracy: 0.6509 - val_loss: 1.6630\n",
      "Epoch 17/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.8082 - loss: 0.7336 - val_accuracy: 0.6509 - val_loss: 1.7449\n",
      "Epoch 18/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.8115 - loss: 0.7185 - val_accuracy: 0.6509 - val_loss: 1.7021\n",
      "Epoch 19/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - accuracy: 0.8100 - loss: 0.7192 - val_accuracy: 0.6509 - val_loss: 1.6314\n",
      "Epoch 20/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.8102 - loss: 0.7146 - val_accuracy: 0.6509 - val_loss: 1.7067\n",
      "Epoch 21/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - accuracy: 0.8103 - loss: 0.7076 - val_accuracy: 0.6509 - val_loss: 1.7562\n",
      "Epoch 22/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.8123 - loss: 0.6987 - val_accuracy: 0.6509 - val_loss: 1.6822\n",
      "Epoch 23/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - accuracy: 0.8069 - loss: 0.7187 - val_accuracy: 0.6509 - val_loss: 1.6632\n",
      "Epoch 24/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 0.8093 - loss: 0.7074 - val_accuracy: 0.6509 - val_loss: 1.7599\n",
      "Epoch 25/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.8102 - loss: 0.7007 - val_accuracy: 0.6509 - val_loss: 1.7145\n",
      "Epoch 26/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - accuracy: 0.8104 - loss: 0.6932 - val_accuracy: 0.6512 - val_loss: 1.6524\n",
      "Epoch 27/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - accuracy: 0.8109 - loss: 0.6935 - val_accuracy: 0.6542 - val_loss: 1.7388\n",
      "Epoch 28/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.8121 - loss: 0.6913 - val_accuracy: 0.6542 - val_loss: 1.7415\n",
      "Epoch 29/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - accuracy: 0.8122 - loss: 0.6870 - val_accuracy: 0.6542 - val_loss: 1.6786\n",
      "Epoch 30/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - accuracy: 0.8122 - loss: 0.6943 - val_accuracy: 0.6542 - val_loss: 1.7122\n",
      "Epoch 31/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.8114 - loss: 0.6906 - val_accuracy: 0.6542 - val_loss: 1.7507\n",
      "Epoch 32/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - accuracy: 0.8142 - loss: 0.6809 - val_accuracy: 0.6542 - val_loss: 1.6901\n",
      "Epoch 33/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 0.8127 - loss: 0.6834 - val_accuracy: 0.6542 - val_loss: 1.6995\n",
      "Epoch 34/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - accuracy: 0.8115 - loss: 0.6931 - val_accuracy: 0.6542 - val_loss: 1.7724\n",
      "Epoch 35/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 0.8122 - loss: 0.6847 - val_accuracy: 0.6542 - val_loss: 1.7186\n",
      "Epoch 36/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.8126 - loss: 0.6786 - val_accuracy: 0.6542 - val_loss: 1.7765\n",
      "Epoch 37/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step - accuracy: 0.8125 - loss: 0.6813 - val_accuracy: 0.6542 - val_loss: 1.7641\n",
      "Epoch 38/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - accuracy: 0.8122 - loss: 0.6757 - val_accuracy: 0.6542 - val_loss: 1.7557\n",
      "Epoch 39/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step - accuracy: 0.8120 - loss: 0.6719 - val_accuracy: 0.6542 - val_loss: 1.7912\n",
      "Epoch 40/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.8119 - loss: 0.6753 - val_accuracy: 0.6542 - val_loss: 1.7636\n",
      "Epoch 41/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step - accuracy: 0.8119 - loss: 0.6683 - val_accuracy: 0.6542 - val_loss: 1.7686\n",
      "Epoch 42/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.8131 - loss: 0.6648 - val_accuracy: 0.6557 - val_loss: 1.7551\n",
      "Epoch 43/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.8159 - loss: 0.6604 - val_accuracy: 0.6557 - val_loss: 1.7108\n",
      "Epoch 44/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 0.8154 - loss: 0.6599 - val_accuracy: 0.6557 - val_loss: 1.7166\n",
      "Epoch 45/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - accuracy: 0.8139 - loss: 0.6643 - val_accuracy: 0.6557 - val_loss: 1.8432\n",
      "Epoch 46/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.8149 - loss: 0.6602 - val_accuracy: 0.6557 - val_loss: 1.6960\n",
      "Epoch 47/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step - accuracy: 0.8159 - loss: 0.6615 - val_accuracy: 0.6557 - val_loss: 1.8210\n",
      "Epoch 48/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404ms/step - accuracy: 0.8162 - loss: 0.6585 - val_accuracy: 0.6557 - val_loss: 1.7123\n",
      "Epoch 49/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.8140 - loss: 0.6563 - val_accuracy: 0.6557 - val_loss: 1.7971\n",
      "Epoch 50/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402ms/step - accuracy: 0.8150 - loss: 0.6523 - val_accuracy: 0.6557 - val_loss: 1.8341\n",
      "Epoch 51/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step - accuracy: 0.8154 - loss: 0.6563 - val_accuracy: 0.6557 - val_loss: 1.7346\n",
      "Epoch 52/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.8149 - loss: 0.6552 - val_accuracy: 0.6557 - val_loss: 1.7920\n",
      "Epoch 53/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - accuracy: 0.8134 - loss: 0.6534 - val_accuracy: 0.6557 - val_loss: 1.8958\n",
      "Epoch 54/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.8166 - loss: 0.6449 - val_accuracy: 0.6542 - val_loss: 1.6771\n",
      "Epoch 55/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step - accuracy: 0.8168 - loss: 0.6505 - val_accuracy: 0.6557 - val_loss: 1.8939\n",
      "Epoch 56/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8145 - loss: 0.6491 - val_accuracy: 0.6557 - val_loss: 1.7400\n",
      "Epoch 57/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step - accuracy: 0.8146 - loss: 0.6461 - val_accuracy: 0.6557 - val_loss: 1.7760\n",
      "Epoch 58/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.8158 - loss: 0.6418 - val_accuracy: 0.6557 - val_loss: 1.8184\n",
      "Epoch 59/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - accuracy: 0.8182 - loss: 0.6351 - val_accuracy: 0.6468 - val_loss: 1.5975\n",
      "Epoch 60/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step - accuracy: 0.8208 - loss: 0.6563 - val_accuracy: 0.6568 - val_loss: 1.9346\n",
      "Epoch 61/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step - accuracy: 0.8147 - loss: 0.6515 - val_accuracy: 0.6578 - val_loss: 1.7720\n",
      "Epoch 62/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - accuracy: 0.8192 - loss: 0.6437 - val_accuracy: 0.6570 - val_loss: 1.8584\n",
      "Epoch 63/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8149 - loss: 0.6394 - val_accuracy: 0.6557 - val_loss: 1.7640\n",
      "Epoch 64/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - accuracy: 0.8148 - loss: 0.6360 - val_accuracy: 0.6557 - val_loss: 1.8128\n",
      "Epoch 65/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step - accuracy: 0.8162 - loss: 0.6365 - val_accuracy: 0.6568 - val_loss: 1.7539\n",
      "Epoch 66/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8179 - loss: 0.6225 - val_accuracy: 0.6575 - val_loss: 1.8015\n",
      "Epoch 67/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step - accuracy: 0.8173 - loss: 0.6284 - val_accuracy: 0.6590 - val_loss: 1.8089\n",
      "Epoch 68/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.8166 - loss: 0.6308 - val_accuracy: 0.6588 - val_loss: 1.8017\n",
      "Epoch 69/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 0.8170 - loss: 0.6257 - val_accuracy: 0.6588 - val_loss: 1.7881\n",
      "Epoch 70/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step - accuracy: 0.8179 - loss: 0.6223 - val_accuracy: 0.6603 - val_loss: 1.7836\n",
      "Epoch 71/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 0.8208 - loss: 0.6203 - val_accuracy: 0.6606 - val_loss: 1.7963\n",
      "Epoch 72/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.8211 - loss: 0.6194 - val_accuracy: 0.6606 - val_loss: 1.7841\n",
      "Epoch 73/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 0.8226 - loss: 0.6196 - val_accuracy: 0.6603 - val_loss: 1.7869\n",
      "Epoch 74/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8206 - loss: 0.6246 - val_accuracy: 0.6603 - val_loss: 1.8423\n",
      "Epoch 75/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8208 - loss: 0.6229 - val_accuracy: 0.6598 - val_loss: 1.8493\n",
      "Epoch 76/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - accuracy: 0.8219 - loss: 0.6160 - val_accuracy: 0.6573 - val_loss: 1.7769\n",
      "Epoch 77/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494ms/step - accuracy: 0.8258 - loss: 0.6079 - val_accuracy: 0.6451 - val_loss: 1.6622\n",
      "Epoch 78/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493ms/step - accuracy: 0.8293 - loss: 0.6084 - val_accuracy: 0.6596 - val_loss: 1.7653\n",
      "Epoch 79/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 0.8215 - loss: 0.6130 - val_accuracy: 0.6562 - val_loss: 1.7561\n",
      "Epoch 80/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 0.8242 - loss: 0.6133 - val_accuracy: 0.6474 - val_loss: 1.7593\n",
      "Epoch 81/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - accuracy: 0.8280 - loss: 0.6209 - val_accuracy: 0.6606 - val_loss: 1.8431\n",
      "Epoch 82/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - accuracy: 0.8241 - loss: 0.6189 - val_accuracy: 0.6613 - val_loss: 1.9005\n",
      "Epoch 83/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - accuracy: 0.8199 - loss: 0.6036 - val_accuracy: 0.6529 - val_loss: 1.7281\n",
      "Epoch 84/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8291 - loss: 0.6086 - val_accuracy: 0.6606 - val_loss: 1.9618\n",
      "Epoch 85/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - accuracy: 0.8234 - loss: 0.6075 - val_accuracy: 0.6590 - val_loss: 1.7904\n",
      "Epoch 86/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8253 - loss: 0.5985 - val_accuracy: 0.6580 - val_loss: 1.8035\n",
      "Epoch 87/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step - accuracy: 0.8289 - loss: 0.5985 - val_accuracy: 0.6616 - val_loss: 1.9231\n",
      "Epoch 88/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 0.8251 - loss: 0.5923 - val_accuracy: 0.6529 - val_loss: 1.7616\n",
      "Epoch 89/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - accuracy: 0.8277 - loss: 0.5991 - val_accuracy: 0.6596 - val_loss: 1.7896\n",
      "Epoch 90/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - accuracy: 0.8280 - loss: 0.5885 - val_accuracy: 0.6583 - val_loss: 1.7924\n",
      "Epoch 91/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step - accuracy: 0.8263 - loss: 0.5931 - val_accuracy: 0.6524 - val_loss: 1.6871\n",
      "Epoch 92/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8313 - loss: 0.5827 - val_accuracy: 0.6568 - val_loss: 1.7013\n",
      "Epoch 93/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8305 - loss: 0.5897 - val_accuracy: 0.6590 - val_loss: 1.7541\n",
      "Epoch 94/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step - accuracy: 0.8303 - loss: 0.5969 - val_accuracy: 0.6593 - val_loss: 1.7510\n",
      "Epoch 95/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.8270 - loss: 0.5842 - val_accuracy: 0.6446 - val_loss: 1.7405\n",
      "Epoch 96/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - accuracy: 0.8358 - loss: 0.5902 - val_accuracy: 0.6514 - val_loss: 1.6813\n",
      "Epoch 97/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step - accuracy: 0.8315 - loss: 0.5793 - val_accuracy: 0.6606 - val_loss: 1.7213\n",
      "Epoch 98/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.8280 - loss: 0.5833 - val_accuracy: 0.6603 - val_loss: 1.8421\n",
      "Epoch 99/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - accuracy: 0.8320 - loss: 0.5846 - val_accuracy: 0.6565 - val_loss: 1.8147\n",
      "Epoch 100/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - accuracy: 0.8340 - loss: 0.5731 - val_accuracy: 0.6568 - val_loss: 1.7306\n",
      "Epoch 101/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.8326 - loss: 0.5735 - val_accuracy: 0.6575 - val_loss: 1.6912\n",
      "Epoch 102/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - accuracy: 0.8329 - loss: 0.5757 - val_accuracy: 0.6453 - val_loss: 1.5596\n",
      "Epoch 103/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.8351 - loss: 0.5765 - val_accuracy: 0.6489 - val_loss: 1.6103\n",
      "Epoch 104/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.8402 - loss: 0.5617 - val_accuracy: 0.6568 - val_loss: 1.7037\n",
      "Epoch 105/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8351 - loss: 0.5714 - val_accuracy: 0.6537 - val_loss: 1.6595\n",
      "Epoch 106/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - accuracy: 0.8334 - loss: 0.5718 - val_accuracy: 0.6517 - val_loss: 1.6913\n",
      "Epoch 107/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 0.8370 - loss: 0.5658 - val_accuracy: 0.6535 - val_loss: 1.7153\n",
      "Epoch 108/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - accuracy: 0.8355 - loss: 0.5617 - val_accuracy: 0.6524 - val_loss: 1.5876\n",
      "Epoch 109/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - accuracy: 0.8356 - loss: 0.5643 - val_accuracy: 0.6596 - val_loss: 1.7527\n",
      "Epoch 110/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - accuracy: 0.8347 - loss: 0.5695 - val_accuracy: 0.6555 - val_loss: 1.7924\n",
      "Epoch 111/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - accuracy: 0.8357 - loss: 0.5649 - val_accuracy: 0.6512 - val_loss: 1.6609\n",
      "Epoch 112/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.8383 - loss: 0.5562 - val_accuracy: 0.6568 - val_loss: 1.7762\n",
      "Epoch 113/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - accuracy: 0.8364 - loss: 0.5671 - val_accuracy: 0.6578 - val_loss: 1.8371\n",
      "Epoch 114/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8372 - loss: 0.5585 - val_accuracy: 0.6504 - val_loss: 1.7042\n",
      "Epoch 115/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 0.8368 - loss: 0.5631 - val_accuracy: 0.6529 - val_loss: 1.6086\n",
      "Epoch 116/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460ms/step - accuracy: 0.8404 - loss: 0.5565 - val_accuracy: 0.6545 - val_loss: 1.7719\n",
      "Epoch 117/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491ms/step - accuracy: 0.8394 - loss: 0.5532 - val_accuracy: 0.6578 - val_loss: 1.7412\n",
      "Epoch 118/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step - accuracy: 0.8375 - loss: 0.5513 - val_accuracy: 0.6529 - val_loss: 1.7415\n",
      "Epoch 119/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step - accuracy: 0.8413 - loss: 0.5452 - val_accuracy: 0.6512 - val_loss: 1.6103\n",
      "Epoch 120/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8417 - loss: 0.5429 - val_accuracy: 0.6532 - val_loss: 1.6899\n",
      "Epoch 121/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471ms/step - accuracy: 0.8433 - loss: 0.5388 - val_accuracy: 0.6537 - val_loss: 1.7655\n",
      "Epoch 122/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8440 - loss: 0.5636 - val_accuracy: 0.6545 - val_loss: 1.7466\n",
      "Epoch 123/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466ms/step - accuracy: 0.8401 - loss: 0.5554 - val_accuracy: 0.6535 - val_loss: 1.6417\n",
      "Epoch 124/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - accuracy: 0.8433 - loss: 0.5386 - val_accuracy: 0.6540 - val_loss: 1.6497\n",
      "Epoch 125/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8455 - loss: 0.5353 - val_accuracy: 0.6565 - val_loss: 1.7662\n",
      "Epoch 126/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - accuracy: 0.8431 - loss: 0.5318 - val_accuracy: 0.6573 - val_loss: 1.6600\n",
      "Epoch 127/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - accuracy: 0.8397 - loss: 0.5412 - val_accuracy: 0.6519 - val_loss: 1.6470\n",
      "Epoch 128/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step - accuracy: 0.8422 - loss: 0.5395 - val_accuracy: 0.6529 - val_loss: 1.7112\n",
      "Epoch 129/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - accuracy: 0.8436 - loss: 0.5307 - val_accuracy: 0.6580 - val_loss: 1.6450\n",
      "Epoch 130/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - accuracy: 0.8418 - loss: 0.5321 - val_accuracy: 0.6545 - val_loss: 1.6654\n",
      "Epoch 131/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step - accuracy: 0.8438 - loss: 0.5354 - val_accuracy: 0.6555 - val_loss: 1.6482\n",
      "Epoch 132/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 0.8443 - loss: 0.5334 - val_accuracy: 0.6550 - val_loss: 1.7138\n",
      "Epoch 133/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - accuracy: 0.8460 - loss: 0.5357 - val_accuracy: 0.6590 - val_loss: 1.8577\n",
      "Epoch 134/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - accuracy: 0.8462 - loss: 0.5472 - val_accuracy: 0.6560 - val_loss: 1.6921\n",
      "Epoch 135/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 514ms/step - accuracy: 0.8438 - loss: 0.5186 - val_accuracy: 0.6535 - val_loss: 1.5987\n",
      "Epoch 136/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - accuracy: 0.8437 - loss: 0.5379 - val_accuracy: 0.6623 - val_loss: 1.6335\n",
      "Epoch 137/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - accuracy: 0.8464 - loss: 0.5222 - val_accuracy: 0.6550 - val_loss: 1.7268\n",
      "Epoch 138/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - accuracy: 0.8446 - loss: 0.5215 - val_accuracy: 0.6611 - val_loss: 1.5552\n",
      "Epoch 139/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 516ms/step - accuracy: 0.8484 - loss: 0.5213 - val_accuracy: 0.6598 - val_loss: 1.6517\n",
      "Epoch 140/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - accuracy: 0.8468 - loss: 0.5185 - val_accuracy: 0.6568 - val_loss: 1.6348\n",
      "Epoch 141/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - accuracy: 0.8457 - loss: 0.5170 - val_accuracy: 0.6613 - val_loss: 1.5652\n",
      "Epoch 142/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - accuracy: 0.8481 - loss: 0.5145 - val_accuracy: 0.6598 - val_loss: 1.6639\n",
      "Epoch 143/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8477 - loss: 0.5155 - val_accuracy: 0.6573 - val_loss: 1.6365\n",
      "Epoch 144/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - accuracy: 0.8488 - loss: 0.5111 - val_accuracy: 0.6601 - val_loss: 1.5695\n",
      "Epoch 145/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 557ms/step - accuracy: 0.8473 - loss: 0.5148 - val_accuracy: 0.6580 - val_loss: 1.5629\n",
      "Epoch 146/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 578ms/step - accuracy: 0.8502 - loss: 0.5077 - val_accuracy: 0.6588 - val_loss: 1.6835\n",
      "Epoch 147/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 561ms/step - accuracy: 0.8485 - loss: 0.5145 - val_accuracy: 0.6570 - val_loss: 1.8262\n",
      "Epoch 148/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - accuracy: 0.8498 - loss: 0.5224 - val_accuracy: 0.6601 - val_loss: 1.6933\n",
      "Epoch 149/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - accuracy: 0.8470 - loss: 0.5130 - val_accuracy: 0.6573 - val_loss: 1.5841\n",
      "Epoch 150/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555ms/step - accuracy: 0.8524 - loss: 0.5002 - val_accuracy: 0.6606 - val_loss: 1.6165\n",
      "Epoch 151/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 571ms/step - accuracy: 0.8504 - loss: 0.5075 - val_accuracy: 0.6596 - val_loss: 1.7393\n",
      "Epoch 152/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 560ms/step - accuracy: 0.8477 - loss: 0.5062 - val_accuracy: 0.6611 - val_loss: 1.5360\n",
      "Epoch 153/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 547ms/step - accuracy: 0.8511 - loss: 0.5023 - val_accuracy: 0.6603 - val_loss: 1.6785\n",
      "Epoch 154/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580ms/step - accuracy: 0.8517 - loss: 0.5050 - val_accuracy: 0.6684 - val_loss: 1.5520\n",
      "Epoch 155/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.8516 - loss: 0.4985 - val_accuracy: 0.6557 - val_loss: 1.6430\n",
      "Epoch 156/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 584ms/step - accuracy: 0.8532 - loss: 0.4946 - val_accuracy: 0.6654 - val_loss: 1.6619\n",
      "Epoch 157/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - accuracy: 0.8547 - loss: 0.4930 - val_accuracy: 0.6598 - val_loss: 1.5681\n",
      "Epoch 158/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - accuracy: 0.8534 - loss: 0.4930 - val_accuracy: 0.6631 - val_loss: 1.7249\n",
      "Epoch 159/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - accuracy: 0.8513 - loss: 0.4937 - val_accuracy: 0.6644 - val_loss: 1.6127\n",
      "Epoch 160/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 531ms/step - accuracy: 0.8559 - loss: 0.4849 - val_accuracy: 0.6682 - val_loss: 1.4912\n",
      "Epoch 161/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - accuracy: 0.8551 - loss: 0.4953 - val_accuracy: 0.6616 - val_loss: 1.7684\n",
      "Epoch 162/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 0.8523 - loss: 0.5002 - val_accuracy: 0.6697 - val_loss: 1.5583\n",
      "Epoch 163/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step - accuracy: 0.8548 - loss: 0.4868 - val_accuracy: 0.6578 - val_loss: 1.6027\n",
      "Epoch 164/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step - accuracy: 0.8570 - loss: 0.4827 - val_accuracy: 0.6733 - val_loss: 1.6131\n",
      "Epoch 165/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - accuracy: 0.8548 - loss: 0.4849 - val_accuracy: 0.6623 - val_loss: 1.5520\n",
      "Epoch 166/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 0.8554 - loss: 0.4792 - val_accuracy: 0.6707 - val_loss: 1.5207\n",
      "Epoch 167/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - accuracy: 0.8574 - loss: 0.4774 - val_accuracy: 0.6657 - val_loss: 1.5496\n",
      "Epoch 168/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - accuracy: 0.8561 - loss: 0.4783 - val_accuracy: 0.6672 - val_loss: 1.6216\n",
      "Epoch 169/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - accuracy: 0.8585 - loss: 0.4768 - val_accuracy: 0.6702 - val_loss: 1.5339\n",
      "Epoch 170/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step - accuracy: 0.8595 - loss: 0.4714 - val_accuracy: 0.6659 - val_loss: 1.5997\n",
      "Epoch 171/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step - accuracy: 0.8581 - loss: 0.4733 - val_accuracy: 0.6725 - val_loss: 1.4814\n",
      "Epoch 172/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - accuracy: 0.8601 - loss: 0.4748 - val_accuracy: 0.6672 - val_loss: 1.5535\n",
      "Epoch 173/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.8583 - loss: 0.4740 - val_accuracy: 0.6707 - val_loss: 1.6324\n",
      "Epoch 174/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8597 - loss: 0.4772 - val_accuracy: 0.6692 - val_loss: 1.5881\n",
      "Epoch 175/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 0.8595 - loss: 0.4738 - val_accuracy: 0.6634 - val_loss: 1.7068\n",
      "Epoch 176/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step - accuracy: 0.8597 - loss: 0.4700 - val_accuracy: 0.6700 - val_loss: 1.6270\n",
      "Epoch 177/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - accuracy: 0.8603 - loss: 0.4613 - val_accuracy: 0.6629 - val_loss: 1.6607\n",
      "Epoch 178/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377ms/step - accuracy: 0.8596 - loss: 0.4656 - val_accuracy: 0.6753 - val_loss: 1.5676\n",
      "Epoch 179/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8619 - loss: 0.4645 - val_accuracy: 0.6695 - val_loss: 1.6173\n",
      "Epoch 180/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step - accuracy: 0.8598 - loss: 0.4685 - val_accuracy: 0.6679 - val_loss: 1.6486\n",
      "Epoch 181/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - accuracy: 0.8617 - loss: 0.4621 - val_accuracy: 0.6723 - val_loss: 1.6597\n",
      "Epoch 182/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8625 - loss: 0.4617 - val_accuracy: 0.6667 - val_loss: 1.6889\n",
      "Epoch 183/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8622 - loss: 0.4941 - val_accuracy: 0.6695 - val_loss: 1.7372\n",
      "Epoch 184/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.8644 - loss: 0.4721 - val_accuracy: 0.6761 - val_loss: 1.5203\n",
      "Epoch 185/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8611 - loss: 0.4582 - val_accuracy: 0.6692 - val_loss: 1.6156\n",
      "Epoch 186/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - accuracy: 0.8629 - loss: 0.4607 - val_accuracy: 0.6768 - val_loss: 1.6200\n",
      "Epoch 187/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - accuracy: 0.8640 - loss: 0.4526 - val_accuracy: 0.6720 - val_loss: 1.6854\n",
      "Epoch 188/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.8640 - loss: 0.4510 - val_accuracy: 0.6720 - val_loss: 1.6318\n",
      "Epoch 189/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 0.8643 - loss: 0.4437 - val_accuracy: 0.6791 - val_loss: 1.5277\n",
      "Epoch 190/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step - accuracy: 0.8663 - loss: 0.4445 - val_accuracy: 0.6738 - val_loss: 1.6318\n",
      "Epoch 191/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.8636 - loss: 0.4492 - val_accuracy: 0.6720 - val_loss: 1.6983\n",
      "Epoch 192/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.8657 - loss: 0.4428 - val_accuracy: 0.6758 - val_loss: 1.5294\n",
      "Epoch 193/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 0.8640 - loss: 0.4487 - val_accuracy: 0.6758 - val_loss: 1.5500\n",
      "Epoch 194/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402ms/step - accuracy: 0.8656 - loss: 0.4418 - val_accuracy: 0.6715 - val_loss: 1.6526\n",
      "Epoch 195/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.8646 - loss: 0.4490 - val_accuracy: 0.6735 - val_loss: 1.6439\n",
      "Epoch 196/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.8663 - loss: 0.4395 - val_accuracy: 0.6799 - val_loss: 1.5239\n",
      "Epoch 197/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - accuracy: 0.8659 - loss: 0.4564 - val_accuracy: 0.6756 - val_loss: 1.4462\n",
      "Epoch 198/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8638 - loss: 0.4911 - val_accuracy: 0.6829 - val_loss: 1.4485\n",
      "Epoch 199/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - accuracy: 0.8667 - loss: 0.4461 - val_accuracy: 0.6697 - val_loss: 1.6790\n",
      "Epoch 200/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - accuracy: 0.8652 - loss: 0.4370 - val_accuracy: 0.6738 - val_loss: 1.6360\n",
      "Epoch 201/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458ms/step - accuracy: 0.8647 - loss: 0.4418 - val_accuracy: 0.6717 - val_loss: 1.8336\n",
      "Epoch 202/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.8645 - loss: 0.4387 - val_accuracy: 0.6773 - val_loss: 1.5712\n",
      "Epoch 203/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - accuracy: 0.8673 - loss: 0.4360 - val_accuracy: 0.6730 - val_loss: 1.6297\n",
      "Epoch 204/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step - accuracy: 0.8674 - loss: 0.4298 - val_accuracy: 0.6819 - val_loss: 1.5145\n",
      "Epoch 205/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.8681 - loss: 0.4316 - val_accuracy: 0.6738 - val_loss: 1.5559\n",
      "Epoch 206/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step - accuracy: 0.8663 - loss: 0.4339 - val_accuracy: 0.6776 - val_loss: 1.5545\n",
      "Epoch 207/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.8680 - loss: 0.4294 - val_accuracy: 0.6791 - val_loss: 1.5288\n",
      "Epoch 208/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8678 - loss: 0.4310 - val_accuracy: 0.6717 - val_loss: 1.6311\n",
      "Epoch 209/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8672 - loss: 0.4315 - val_accuracy: 0.6771 - val_loss: 1.5409\n",
      "Epoch 210/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - accuracy: 0.8693 - loss: 0.4287 - val_accuracy: 0.6728 - val_loss: 1.6680\n",
      "Epoch 211/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8691 - loss: 0.4257 - val_accuracy: 0.6811 - val_loss: 1.5894\n",
      "Epoch 212/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.8704 - loss: 0.4289 - val_accuracy: 0.6758 - val_loss: 1.5563\n",
      "Epoch 213/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8707 - loss: 0.4397 - val_accuracy: 0.6751 - val_loss: 1.6675\n",
      "Epoch 214/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step - accuracy: 0.8709 - loss: 0.4580 - val_accuracy: 0.6781 - val_loss: 1.5408\n",
      "Epoch 215/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.8706 - loss: 0.4212 - val_accuracy: 0.6717 - val_loss: 1.7324\n",
      "Epoch 216/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.8678 - loss: 0.4207 - val_accuracy: 0.6789 - val_loss: 1.6410\n",
      "Epoch 217/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - accuracy: 0.8731 - loss: 0.4136 - val_accuracy: 0.6758 - val_loss: 1.7231\n",
      "Epoch 218/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 0.8720 - loss: 0.4174 - val_accuracy: 0.6710 - val_loss: 1.8030\n",
      "Epoch 219/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - accuracy: 0.8718 - loss: 0.4157 - val_accuracy: 0.6778 - val_loss: 1.6509\n",
      "Epoch 220/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - accuracy: 0.8740 - loss: 0.4084 - val_accuracy: 0.6786 - val_loss: 1.6287\n",
      "Epoch 221/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step - accuracy: 0.8724 - loss: 0.4118 - val_accuracy: 0.6832 - val_loss: 1.4985\n",
      "Epoch 222/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - accuracy: 0.8740 - loss: 0.4143 - val_accuracy: 0.6756 - val_loss: 1.6322\n",
      "Epoch 223/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.8735 - loss: 0.4127 - val_accuracy: 0.6824 - val_loss: 1.6211\n",
      "Epoch 224/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step - accuracy: 0.8724 - loss: 0.4066 - val_accuracy: 0.6811 - val_loss: 1.5764\n",
      "Epoch 225/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8740 - loss: 0.4062 - val_accuracy: 0.6801 - val_loss: 1.6425\n",
      "Epoch 226/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.8732 - loss: 0.4081 - val_accuracy: 0.6791 - val_loss: 1.6048\n",
      "Epoch 227/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - accuracy: 0.8746 - loss: 0.4073 - val_accuracy: 0.6796 - val_loss: 1.6148\n",
      "Epoch 228/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - accuracy: 0.8749 - loss: 0.4102 - val_accuracy: 0.6791 - val_loss: 1.6547\n",
      "Epoch 229/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.8736 - loss: 0.4119 - val_accuracy: 0.6712 - val_loss: 1.5447\n",
      "Epoch 230/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.8728 - loss: 0.4466 - val_accuracy: 0.6893 - val_loss: 1.3466\n",
      "Epoch 231/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step - accuracy: 0.8692 - loss: 0.4251 - val_accuracy: 0.6865 - val_loss: 1.4661\n",
      "Epoch 232/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.8743 - loss: 0.4109 - val_accuracy: 0.6745 - val_loss: 1.7769\n",
      "Epoch 233/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8731 - loss: 0.4039 - val_accuracy: 0.6819 - val_loss: 1.5552\n",
      "Epoch 234/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.8732 - loss: 0.4053 - val_accuracy: 0.6720 - val_loss: 1.7378\n",
      "Epoch 235/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - accuracy: 0.8736 - loss: 0.4048 - val_accuracy: 0.6822 - val_loss: 1.6171\n",
      "Epoch 236/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step - accuracy: 0.8742 - loss: 0.3958 - val_accuracy: 0.6862 - val_loss: 1.5465\n",
      "Epoch 237/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - accuracy: 0.8752 - loss: 0.4033 - val_accuracy: 0.6773 - val_loss: 1.5947\n",
      "Epoch 238/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.8743 - loss: 0.3965 - val_accuracy: 0.6806 - val_loss: 1.5747\n",
      "Epoch 239/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.8783 - loss: 0.3896 - val_accuracy: 0.6758 - val_loss: 1.6476\n",
      "Epoch 240/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - accuracy: 0.8750 - loss: 0.3994 - val_accuracy: 0.6789 - val_loss: 1.8620\n",
      "Epoch 241/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.8753 - loss: 0.4356 - val_accuracy: 0.6794 - val_loss: 1.7060\n",
      "Epoch 242/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 0.8755 - loss: 0.4127 - val_accuracy: 0.6870 - val_loss: 1.6193\n",
      "Epoch 243/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8759 - loss: 0.3964 - val_accuracy: 0.6817 - val_loss: 1.5767\n",
      "Epoch 244/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step - accuracy: 0.8784 - loss: 0.3856 - val_accuracy: 0.6811 - val_loss: 1.8353\n",
      "Epoch 245/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - accuracy: 0.8748 - loss: 0.3972 - val_accuracy: 0.6763 - val_loss: 1.7995\n",
      "Epoch 246/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.8751 - loss: 0.3949 - val_accuracy: 0.6776 - val_loss: 1.7835\n",
      "Epoch 247/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.8763 - loss: 0.3877 - val_accuracy: 0.6837 - val_loss: 1.7190\n",
      "Epoch 248/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.8781 - loss: 0.3884 - val_accuracy: 0.6789 - val_loss: 1.7497\n",
      "Epoch 249/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 0.8787 - loss: 0.3856 - val_accuracy: 0.6824 - val_loss: 1.6294\n",
      "Epoch 250/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step - accuracy: 0.8806 - loss: 0.3814 - val_accuracy: 0.6794 - val_loss: 1.6369\n",
      "Epoch 251/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.8825 - loss: 0.3778 - val_accuracy: 0.6817 - val_loss: 1.7010\n",
      "Epoch 252/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - accuracy: 0.8786 - loss: 0.3816 - val_accuracy: 0.6799 - val_loss: 1.6913\n",
      "Epoch 253/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 0.8777 - loss: 0.3873 - val_accuracy: 0.6799 - val_loss: 1.6969\n",
      "Epoch 254/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - accuracy: 0.8808 - loss: 0.3751 - val_accuracy: 0.6834 - val_loss: 1.6218\n",
      "Epoch 255/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8809 - loss: 0.3772 - val_accuracy: 0.6768 - val_loss: 1.8178\n",
      "Epoch 256/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.8829 - loss: 0.3720 - val_accuracy: 0.6801 - val_loss: 1.6695\n",
      "Epoch 257/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 0.8821 - loss: 0.3742 - val_accuracy: 0.6834 - val_loss: 1.6286\n",
      "Epoch 258/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.8815 - loss: 0.3745 - val_accuracy: 0.6776 - val_loss: 1.7049\n",
      "Epoch 259/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.8776 - loss: 0.3963 - val_accuracy: 0.6758 - val_loss: 1.7423\n",
      "Epoch 260/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.8798 - loss: 0.3979 - val_accuracy: 0.6827 - val_loss: 1.6947\n",
      "Epoch 261/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - accuracy: 0.8821 - loss: 0.3883 - val_accuracy: 0.6900 - val_loss: 1.5351\n",
      "Epoch 262/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - accuracy: 0.8834 - loss: 0.3657 - val_accuracy: 0.6758 - val_loss: 1.8269\n",
      "Epoch 263/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - accuracy: 0.8706 - loss: 0.4717 - val_accuracy: 0.6705 - val_loss: 1.7649\n",
      "Epoch 264/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - accuracy: 0.8545 - loss: 0.5215 - val_accuracy: 0.6745 - val_loss: 1.7776\n",
      "Epoch 265/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.8694 - loss: 0.4435 - val_accuracy: 0.6852 - val_loss: 1.7180\n",
      "Epoch 266/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - accuracy: 0.8814 - loss: 0.3719 - val_accuracy: 0.6857 - val_loss: 1.6453\n",
      "Epoch 267/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 0.8821 - loss: 0.3728 - val_accuracy: 0.6842 - val_loss: 1.6222\n",
      "Epoch 268/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - accuracy: 0.8795 - loss: 0.3740 - val_accuracy: 0.6761 - val_loss: 1.8306\n",
      "Epoch 269/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - accuracy: 0.8821 - loss: 0.3667 - val_accuracy: 0.6890 - val_loss: 1.6818\n",
      "Epoch 270/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - accuracy: 0.8814 - loss: 0.3731 - val_accuracy: 0.6789 - val_loss: 1.7649\n",
      "Epoch 271/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - accuracy: 0.8821 - loss: 0.3662 - val_accuracy: 0.6905 - val_loss: 1.6386\n",
      "Epoch 272/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.8835 - loss: 0.3667 - val_accuracy: 0.6804 - val_loss: 1.7107\n",
      "Epoch 273/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - accuracy: 0.8834 - loss: 0.3686 - val_accuracy: 0.6860 - val_loss: 1.6995\n",
      "Epoch 274/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - accuracy: 0.8820 - loss: 0.3739 - val_accuracy: 0.6794 - val_loss: 1.6510\n",
      "Epoch 275/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step - accuracy: 0.8849 - loss: 0.3625 - val_accuracy: 0.6893 - val_loss: 1.5087\n",
      "Epoch 276/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - accuracy: 0.8868 - loss: 0.3634 - val_accuracy: 0.6878 - val_loss: 1.5732\n",
      "Epoch 277/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step - accuracy: 0.8841 - loss: 0.3680 - val_accuracy: 0.6819 - val_loss: 1.5907\n",
      "Epoch 278/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - accuracy: 0.8832 - loss: 0.3691 - val_accuracy: 0.6862 - val_loss: 1.6148\n",
      "Epoch 279/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8853 - loss: 0.3608 - val_accuracy: 0.6819 - val_loss: 1.5867\n",
      "Epoch 280/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - accuracy: 0.8839 - loss: 0.3657 - val_accuracy: 0.6900 - val_loss: 1.4497\n",
      "Epoch 281/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.8855 - loss: 0.3611 - val_accuracy: 0.6768 - val_loss: 1.7090\n",
      "Epoch 282/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - accuracy: 0.8876 - loss: 0.3542 - val_accuracy: 0.6834 - val_loss: 1.6645\n",
      "Epoch 283/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - accuracy: 0.8867 - loss: 0.3538 - val_accuracy: 0.6865 - val_loss: 1.7170\n",
      "Epoch 284/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399ms/step - accuracy: 0.8874 - loss: 0.3520 - val_accuracy: 0.6804 - val_loss: 1.7327\n",
      "Epoch 285/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8891 - loss: 0.3525 - val_accuracy: 0.6796 - val_loss: 1.6559\n",
      "Epoch 286/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - accuracy: 0.8900 - loss: 0.3617 - val_accuracy: 0.6865 - val_loss: 1.6373\n",
      "Epoch 287/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - accuracy: 0.8892 - loss: 0.3482 - val_accuracy: 0.6827 - val_loss: 1.7612\n",
      "Epoch 288/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - accuracy: 0.8885 - loss: 0.3620 - val_accuracy: 0.6786 - val_loss: 1.7679\n",
      "Epoch 289/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - accuracy: 0.8876 - loss: 0.3873 - val_accuracy: 0.6870 - val_loss: 1.5738\n",
      "Epoch 290/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555ms/step - accuracy: 0.8898 - loss: 0.3587 - val_accuracy: 0.6819 - val_loss: 1.7255\n",
      "Epoch 291/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 518ms/step - accuracy: 0.8880 - loss: 0.3538 - val_accuracy: 0.6860 - val_loss: 1.5057\n",
      "Epoch 292/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 533ms/step - accuracy: 0.8877 - loss: 0.3499 - val_accuracy: 0.6860 - val_loss: 1.7360\n",
      "Epoch 293/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - accuracy: 0.8868 - loss: 0.3503 - val_accuracy: 0.6832 - val_loss: 1.6769\n",
      "Epoch 294/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - accuracy: 0.8903 - loss: 0.3420 - val_accuracy: 0.6867 - val_loss: 1.7181\n",
      "Epoch 295/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step - accuracy: 0.8890 - loss: 0.3424 - val_accuracy: 0.6778 - val_loss: 1.7578\n",
      "Epoch 296/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.8895 - loss: 0.3456 - val_accuracy: 0.6814 - val_loss: 1.7879\n",
      "Epoch 297/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - accuracy: 0.8918 - loss: 0.3366 - val_accuracy: 0.6855 - val_loss: 1.6438\n",
      "Epoch 298/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - accuracy: 0.8916 - loss: 0.3398 - val_accuracy: 0.6773 - val_loss: 1.7431\n",
      "Epoch 299/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - accuracy: 0.8882 - loss: 0.3460 - val_accuracy: 0.6847 - val_loss: 1.6409\n",
      "Epoch 300/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.8888 - loss: 0.3429 - val_accuracy: 0.6832 - val_loss: 1.5370\n",
      "Epoch 301/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.8918 - loss: 0.3463 - val_accuracy: 0.6819 - val_loss: 1.6006\n",
      "Epoch 302/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - accuracy: 0.8915 - loss: 0.3473 - val_accuracy: 0.6885 - val_loss: 1.5691\n",
      "Epoch 303/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - accuracy: 0.8929 - loss: 0.3426 - val_accuracy: 0.6880 - val_loss: 1.4585\n",
      "Epoch 304/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step - accuracy: 0.8944 - loss: 0.3359 - val_accuracy: 0.6883 - val_loss: 1.5621\n",
      "Epoch 305/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - accuracy: 0.8932 - loss: 0.3356 - val_accuracy: 0.6857 - val_loss: 1.5184\n",
      "Epoch 306/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8937 - loss: 0.3346 - val_accuracy: 0.6867 - val_loss: 1.5272\n",
      "Epoch 307/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8927 - loss: 0.3334 - val_accuracy: 0.6857 - val_loss: 1.6110\n",
      "Epoch 308/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - accuracy: 0.8932 - loss: 0.3284 - val_accuracy: 0.6796 - val_loss: 1.7014\n",
      "Epoch 309/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - accuracy: 0.8963 - loss: 0.3269 - val_accuracy: 0.6860 - val_loss: 1.6236\n",
      "Epoch 310/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8931 - loss: 0.3287 - val_accuracy: 0.6890 - val_loss: 1.6162\n",
      "Epoch 311/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.8938 - loss: 0.3276 - val_accuracy: 0.6827 - val_loss: 1.6441\n",
      "Epoch 312/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step - accuracy: 0.8955 - loss: 0.3229 - val_accuracy: 0.6829 - val_loss: 1.6613\n",
      "Epoch 313/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399ms/step - accuracy: 0.8962 - loss: 0.3244 - val_accuracy: 0.6781 - val_loss: 1.6985\n",
      "Epoch 314/5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - accuracy: 0.8973 - loss: 0.3200 - val_accuracy: 0.6766 - val_loss: 1.8015\n",
      "Epoch 315/5000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8986 - loss: 0.3094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(j \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     14\u001b[0m             decoder_target_data[i, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder_input_data = np.zeros((len(X), max_encoder, len(X_voc)), dtype=\"float\")\n",
    "for i, line in enumerate(X):\n",
    "    for j, k in enumerate(line):\n",
    "        encoder_input_data[i][j][k] = 1.0\n",
    "        \n",
    "decoder_input_data = np.zeros((len(X), max_decoder, len(y_voc)), dtype=\"float\")\n",
    "decoder_target_data = np.zeros((len(X), max_decoder, len(y_voc)), dtype=\"float\")\n",
    "for i, line in enumerate(y):\n",
    "    for j, k in enumerate(line):\n",
    "        decoder_input_data[i, j, k] = 1.0\n",
    "        if(j > 0):\n",
    "            decoder_target_data[i, j-1, k] = 1.0\n",
    "            \n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output # Lstm 1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3] # Lstm 2\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4] # Dense Layer\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq):\n",
    "    \n",
    "    # Encoder\n",
    "    state_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(y_voc)))\n",
    "    target_seq[0, 0, target_tok_enc[\"\\t\"]] = 1.0\n",
    "    \n",
    "    stop = False\n",
    "    decode_sent = \"\"\n",
    "    \n",
    "    while not stop:\n",
    "        \n",
    "        output_tok, h, c = decoder_model.predict([target_seq] + state_value, verbose=0)\n",
    "        \n",
    "        sample_token_idx = np.argmax(output_tok[0, -1, :])\n",
    "        sample_char = target_tok_dec[sample_token_idx]\n",
    "        \n",
    "        decode_sent += sample_char\n",
    "        \n",
    "        if sample_char == \"\\n\" or len(decode_sent) > max_decoder:\n",
    "            stop = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1, len(y_voc)))\n",
    "        target_seq[0, 0, sample_token_idx] = 1.0\n",
    "        \n",
    "        state_value = [h, c]\n",
    "        \n",
    "    return decode_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Seq :  நான் தூங்கினேன்.\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  அமைதியாக இருங்கள்\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  நான் நடப்பேன்.\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  அவன் யார்?\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  யாருக்குத் தெரியும்?\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  அவள் சிரித்தாள்\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  என்னிடம் பேசு\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  அவள் யார்?\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  போய் தூங்கு\n",
      "Output Seq :  I                                                                                                \n",
      "Input Seq :  மழை பெய்யலாம்\n",
      "Output Seq :  I                                                                                                \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    input_seq = encoder_input_data[i: i+1]\n",
    "    d_seq = decode_seq(input_seq)\n",
    "    \n",
    "    print(\"Input Seq : \", X_txt[i])\n",
    "    print(\"Output Seq : \", d_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  நான் மிகவும் சந்த ாஷமாக இருக்கிதேன\n",
      "Output :  I                                                                                                \n",
      "Input :  அது அவசியமில்லை\n",
      "Output :  e                                                                                                \n",
      "Input :  தயவுசெய்து அல மீண்டும் சசய்யவும\n",
      "Output :  I                                                                                                \n",
      "Input :  அது ஒரு நல்ை தயாசலை\n",
      "Output :  I                                                                                                \n",
      "Input :  அவர்கள் ஒன்ோக தவலை சசய்ய ஒப்புக்சகாண்டைர\n",
      "Output :  I                                                                                                \n"
     ]
    }
   ],
   "source": [
    "# Unseen data\n",
    "def inf_testing(text):\n",
    "    # Tokenize\n",
    "    tok = [input_tok_enc.get(char, input_tok_enc[\" \"]) for char in text]\n",
    "    \n",
    "    # Encoder Input Fmt\n",
    "    encoder_inp_seq = np.zeros((1, len(tok), len(X_voc)), dtype=\"float\")\n",
    "    for i, j in enumerate(tok):\n",
    "        encoder_inp_seq[0][i][j] = 1.0\n",
    "        \n",
    "    output = decode_seq(encoder_inp_seq)\n",
    "    \n",
    "    print(\"Input : \", text)\n",
    "    print(\"Output : \", output)\n",
    "    \n",
    "\n",
    "lst = [\"நான் மிகவும் சந்த ாஷமாக இருக்கிதேன\", \"அது அவசியமில்லை\", \"தயவுசெய்து அல மீண்டும் சசய்யவும\", \"அது ஒரு நல்ை தயாசலை\", \"அவர்கள் ஒன்ோக தவலை சசய்ய ஒப்புக்சகாண்டைர\"]\n",
    "for sent in lst:\n",
    "    inf_testing(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
